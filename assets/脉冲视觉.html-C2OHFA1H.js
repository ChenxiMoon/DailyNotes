import{_ as n,c as p,a as i,o as s}from"./app-4EFUGk8x.js";const e={};function r(l,a){return s(),p("div",null,a[0]||(a[0]=[i('<h1 id="三个问题" tabindex="-1"><a class="header-anchor" href="#三个问题"><span>三个问题</span></a></h1><h2 id="脉冲视觉的工作原理" tabindex="-1"><a class="header-anchor" href="#脉冲视觉的工作原理"><span>脉冲视觉的工作原理？</span></a></h2><ol><li>脉冲视觉（Spike Vision）是由北京大学黄铁军教授的团队提出的一种全新的视觉信息表达体系，旨在克服传统视频成像的局限性 。它的核心原理是模拟生物视觉系统，通过一种“光子累积和阈值触发”的机制来捕捉和编码视觉信息</li></ol><h3 id="脉冲视觉的工作原理是对传统摄像机基于-帧-的成像模式的颠覆-。它不采用固定的曝光时间和同步快门-而是模拟生物视网膜的感光方式-其核心原理是" tabindex="-1"><a class="header-anchor" href="#脉冲视觉的工作原理是对传统摄像机基于-帧-的成像模式的颠覆-。它不采用固定的曝光时间和同步快门-而是模拟生物视网膜的感光方式-其核心原理是"><span>脉冲视觉的工作原理是对传统摄像机基于“帧”的成像模式的颠覆 。它不采用固定的曝光时间和同步快门，而是模拟生物视网膜的感光方式 ，其核心原理是：</span></a></h3><p>持续捕获光子，异步产生脉冲：脉冲视觉的感光器件是持续工作的，它不断捕获并累积光子能量 。</p><p>达到阈值即发放：当某个感光单元累积的光子能量达到了一个预先设定的阈值时，它就会瞬间产生一个脉冲（或称为“事件”），然后能量清零，重新开始下一次的累积 。</p><p>脉冲时间编码光强：脉冲产生的时间间隔蕴含了光照的强度信息 。光线越强，能量累积得越快，达到阈值产生脉冲的时间就越短；反之，光线越弱，产生脉冲所需的时间就越长 。</p><p>简单来说，传统相机像是每隔一段时间（例如 1/30 秒）集体拍一张合影 ，而脉冲相机则像是每个感光单元有了光强变化就立刻“举手”报告一次，完全不受“帧率”的限制 。这种机制使得脉冲视觉能够以极高的时间分辨率来记录光的变化过程 。</p><h3 id="详细原理和与传统视频的区别" tabindex="-1"><a class="header-anchor" href="#详细原理和与传统视频的区别"><span>详细原理和与传统视频的区别</span></a></h3><ol><li>感光和脉冲生成机制：</li></ol><ul><li><p><strong>传统视频：</strong> 传统相机的成像模型是所有感光单元在预定的帧率下（例如几十 Hz），同步进行持续时长相同的曝光，然后将累积的光强记录下来，形成一帧图像 。这种方式会丢失两次曝光之间所有光线的变化过程 。</p></li><li><p><strong>脉冲视觉：</strong> 脉冲视觉模型中的感光器件会<strong>持续</strong>捕获光子 。当累积的光强超过一个预设的</p><p><strong>阈值</strong>时，它就会<strong>异步</strong>地产生一个脉冲 。这种产生脉冲和其持续时长的过程，被称为一个**“视元”**</p></li></ul><ol start="2"><li>信息编码方式：</li></ol><ul><li><strong>传统视频：</strong> 图像通过记录曝光时间内的平均光强来表达视觉信息 。这导致图像无法记录光线变化的过程 。</li><li><strong>脉冲视觉：</strong> 脉冲视觉将光强信息编码在了脉冲的<strong>时间间隔</strong>中 。 <ul><li>脉冲生成的时间越长，表明接收到的光信号越弱 。</li><li>反之，脉冲生成的时间越短，光信号就越强 。</li><li>这种方式使得脉冲流具有清晰的物理意义，可以用来估计任意时刻的光强 。</li></ul></li></ul><ol start="3"><li>时域采样和“全时成像”：</li></ol><ul><li><p><strong>传统视频：</strong> 视频的时域采样率是人为规定的，比如数十 Hz，且两帧图像之间的信息是完全丢失的 。</p></li><li><p><strong>脉冲视觉：</strong> 脉冲相机不采用同步曝光，而是持续捕获光子 。每个感光器件产生的脉冲按照时间次序排成序列，所有感光器件的脉冲序列组成</p></li><li><p><strong>脉冲流阵列</strong>，这就是脉冲视觉的表达形式——<strong>“视达（Vidar）”</strong>，用以代替传统的视频（Video） 。</p></li><li><p>由于视达有效保留了各个采样位置光线的时域变化过程，可以从脉冲流中重构出</p><p><strong>任意时刻的画面</strong> 。这种能力被称为**“全时成像”（fulltime imaging）**或连续成像（continuous imaging）</p></li></ul><h3 id="脉冲视觉的突出优势" tabindex="-1"><a class="header-anchor" href="#脉冲视觉的突出优势"><span>脉冲视觉的突出优势</span></a></h3><ul><li><strong>超高速：</strong> 脉冲视觉可以实现千万 Hz 的高速时域采样，能够捕捉传统相机无法记录的极快物理过程 。例如，北京大学开发的芯片已能清晰拍摄时速 350km 的高铁和每分钟 7200 转的硬盘 。</li><li><strong>全时：</strong> 脉冲流蕴含了任意时刻的影像能力，可以重构出连续的画面，就像人脑对外部环境的连续感知一样 。</li><li><strong>高动态范围：</strong> 脉冲视觉通过积分采样原理，可以对场景中亮处和暗处的信息都能进行保留，为实现高动态范围成像提供了可能 。</li><li><strong>宽频成像</strong>： 利用相机的高频能力，可以获得各像素的振动频率，从而区分不同目标（如螺旋桨、抖动、海浪等） 。</li></ul><h2 id="脉冲是怎么成像的" tabindex="-1"><a class="header-anchor" href="#脉冲是怎么成像的"><span>脉冲是怎么成像的？</span></a></h2><h3 id="脉冲本身并不是图像-而是包含了光强和时间信息的数据流-称为-视达-vidar-。-从这种脉冲流中重建出我们所见的图像-即-成像-主要依赖于对脉冲时间的分析和计算。" tabindex="-1"><a class="header-anchor" href="#脉冲本身并不是图像-而是包含了光强和时间信息的数据流-称为-视达-vidar-。-从这种脉冲流中重建出我们所见的图像-即-成像-主要依赖于对脉冲时间的分析和计算。"><span>脉冲本身并不是图像，而是包含了光强和时间信息的数据流，称为“视达 (Vidar)” 。 从这种脉冲流中重建出我们所见的图像（即“成像”），主要依赖于对脉冲时间的分析和计算。</span></a></h3><h3 id="成像的过程被称为-脉冲影像重建-论文中提到了几种主要方法" tabindex="-1"><a class="header-anchor" href="#成像的过程被称为-脉冲影像重建-论文中提到了几种主要方法"><span>成像的过程被称为“脉冲影像重建” ，论文中提到了几种主要方法：</span></a></h3><h4 id="全时成像-full-time-imaging-这是脉冲视觉最核心的成像能力-。因为每个脉冲的持续时间都与光线强度成反比-所以理论上可以根据这个关系估计出任意时刻的光强值-从而重建出任意时刻的精细图像-。" tabindex="-1"><a class="header-anchor" href="#全时成像-full-time-imaging-这是脉冲视觉最核心的成像能力-。因为每个脉冲的持续时间都与光线强度成反比-所以理论上可以根据这个关系估计出任意时刻的光强值-从而重建出任意时刻的精细图像-。"><span>全时成像 (Full-time Imaging)：这是脉冲视觉最核心的成像能力 。因为每个脉冲的持续时间都与光线强度成反比，所以理论上可以根据这个关系估计出任意时刻的光强值，从而重建出任意时刻的精细图像 。</span></a></h4><h3 id="基础重建算法" tabindex="-1"><a class="header-anchor" href="#基础重建算法"><span>基础重建算法：</span></a></h3><p>基于脉冲间隔法 (TFI)：直接利用“脉冲间隔越短，光强越强”这一特性来计算瞬时的光强，但这种方法容易受光子波动影响，产生噪声 。</p><p>基于时间窗平均法 (TFW)：在一定时间窗口内统计脉冲的数量来计算平均光强 。这种方法对静态场景成像更稳定，但如果物体在高速运动，则会产生运动模糊 。</p><p>高级重建算法：为了克服基础算法的缺点，研究人员提出了更复杂的算法 。例如，通过运动补偿对脉冲数据进行滤波，可以在提升信噪比的同时避免运动模糊 ；或者利用脉冲神经网络模型来提升图像的对比度 。</p><h3 id="总结来说-脉冲成像是通过解码每个像素点产生的脉冲序列的时间信息-反推出该点在任意时刻的光照强度-最终将所有像素点的光强分布组合起来-形成一幅完整的图像。" tabindex="-1"><a class="header-anchor" href="#总结来说-脉冲成像是通过解码每个像素点产生的脉冲序列的时间信息-反推出该点在任意时刻的光照强度-最终将所有像素点的光强分布组合起来-形成一幅完整的图像。"><span>总结来说，脉冲成像是通过解码每个像素点产生的脉冲序列的时间信息，反推出该点在任意时刻的光照强度，最终将所有像素点的光强分布组合起来，形成一幅完整的图像。</span></a></h3><h2 id="讲出三种脉冲成像的算法以及区别" tabindex="-1"><a class="header-anchor" href="#讲出三种脉冲成像的算法以及区别"><span>讲出三种脉冲成像的算法以及区别</span></a></h2><p>脉冲成像（Spike Imaging）常用的三类典型算法主要是围绕 如何从脉冲序列（spike stream）恢复高质量图像 展开的，不同算法在建模思路、利用信息的方式、以及计算复杂度上有区别。常见三种方法及区别如下：</p><ol><li>累积重建（Integration-based Reconstruction） 原理</li></ol><p>将脉冲序列在时间维度上进行积分（累加），利用脉冲发射的频率与光强成正比的特性来恢复图像。</p><p>通常会在固定时间窗内统计每个像素的脉冲数量，直接映射为灰度值。</p><p>特点</p><p>优点：简单高效，实时性强（可以直接流式处理）。</p><p>缺点：容易产生运动模糊，时间窗大小选取敏感；噪声脉冲会直接影响图像质量。</p><p>典型场景</p><p>高速运动场景的粗略成像、低延迟目标检测。</p><ol start="2"><li>事件驱动滤波重建（Event-driven Filtering / Spike-based Filtering） 原理</li></ol><p>在脉冲信号的时间序列上应用滤波器（如指数衰减滤波、时空高斯滤波等）进行平滑与去噪。</p><p>通过滤波器的响应计算像素的瞬时光强，减少噪声并保留细节。</p><p>特点</p><p>优点：能在保持高时间分辨率的同时，抑制噪声。</p><p>缺点：滤波器参数（时间常数、空间核大小）需要精心调节；计算量比简单累积大。</p><p>典型场景</p><p>动态范围大、噪声较多的环境；需要较高空间清晰度的场景。</p><ol start="3"><li>深度学习重建（Deep Learning-based Spike Reconstruction） 原理</li></ol><p>将脉冲序列（可按时间片分割）输入神经网络（如 UNet、Spiking Neural Network、Transformer 等）进行端到端的成像重建。</p><p>网络会自动学习时空特征映射关系，将稀疏的二值脉冲转为连续高质量图像。</p><p>特点</p><p>优点：重建质量高，能够恢复纹理和细节，抗噪能力强。</p><p>缺点：需要大量标注数据训练；推理速度可能较慢，硬件要求高。</p><p>典型场景</p><p>超高速高质量成像、科研实验、需要恢复细节的视觉任务。</p><h3 id="好的老板-根据您提供的这份文档-其中一共示范和介绍了-7-个具体的算法。" tabindex="-1"><a class="header-anchor" href="#好的老板-根据您提供的这份文档-其中一共示范和介绍了-7-个具体的算法。"><span>好的老板，根据您提供的这份文档，其中一共示范和介绍了 7 个具体的算法。</span></a></h3><p>这些算法可以按照任务类型归纳如下：</p><ol><li>纹理重构与超分辨率 (5 个算法) 这部分算法的目标是从脉冲数据中恢复出清晰的图像或视频。</li></ol><p>TFI 算法：用于超高速运动场景的纹理重构 。</p><p>TFP 算法：同样用于超高速运动场景的纹理重构 。</p><p>TFSTP 算法：也是一种用于高速场景的纹理重构算法 。</p><p>SSML 算法：一种用于真实场景重构的神经网络算法 (SSML_ReconNet)，特点是训练时不需要真值（GroundTruth） 。</p><p>SRR 算法：一种超分辨率重构算法 (SRR_model)，可以生成比原始分辨率更高的图像，需要 Pyflow 库来计算光流 。</p><ol start="2"><li>光流估计 (1 个算法) 这类算法用于计算场景中物体的运动速度和方向。</li></ol><p>SCFlow 算法：一个用于从脉冲数据中估计光流的神经网络 。</p><ol start="3"><li>多目标跟踪 (1 个算法) 这类算法用于在场景中同时跟踪多个高速运动的物体。</li></ol><p>SpikeSORT 算法：一个多目标跟踪器，文档中用它在 motVidarReal2020 数据集上进行了演示 。</p><h2 id="想法" tabindex="-1"><a class="header-anchor" href="#想法"><span>想法</span></a></h2><p>黄教授团队的“脉冲视觉”研究从基础理论方面突破，变革了已经沿用两个世纪的传统感光方式，</p><h3 id="使得每个新型感光元器件可以每个像素单独对光子进行捕获-并可以重现拍摄时任意时刻的清晰图像。也就是说-有了脉冲相机-也许以后都不会再谈帧率了-因为拍摄到的信息将无限接近现实的光的运动-其时域采样率为-4-万赫兹-这是以前所有动辄上百万的高帧率相机都无法比拟的。此外-脉冲相机的感光元件可以利用现有的-cmos-制造技术上进行制造-使得成本可以控制得比较低。这项技术可以说意义非凡-前景广泛。" tabindex="-1"><a class="header-anchor" href="#使得每个新型感光元器件可以每个像素单独对光子进行捕获-并可以重现拍摄时任意时刻的清晰图像。也就是说-有了脉冲相机-也许以后都不会再谈帧率了-因为拍摄到的信息将无限接近现实的光的运动-其时域采样率为-4-万赫兹-这是以前所有动辄上百万的高帧率相机都无法比拟的。此外-脉冲相机的感光元件可以利用现有的-cmos-制造技术上进行制造-使得成本可以控制得比较低。这项技术可以说意义非凡-前景广泛。"><span>使得每个新型感光元器件可以每个像素单独对光子进行捕获，并可以重现拍摄时任意时刻的清晰图像。也就是说，有了脉冲相机，也许以后都不会再谈帧率了，因为拍摄到的信息将无限接近现实的光的运动，其时域采样率为 4 万赫兹，这是以前所有动辄上百万的高帧率相机都无法比拟的。此外，脉冲相机的感光元件可以利用现有的 CMOS 制造技术上进行制造，使得成本可以控制得比较低。这项技术可以说意义非凡，前景广泛。</span></a></h3><h3 id="接着-脉冲相机在高铁检修、涡轮停机检修等方面的应用。我比较感兴趣的是基于脉冲的视觉任务。传统计算机视觉基于的图像、视频等基本是用传统相机拍摄的-当然也不排除用特殊成像方式的-在计算机中图像通常以像素矩阵存储" tabindex="-1"><a class="header-anchor" href="#接着-脉冲相机在高铁检修、涡轮停机检修等方面的应用。我比较感兴趣的是基于脉冲的视觉任务。传统计算机视觉基于的图像、视频等基本是用传统相机拍摄的-当然也不排除用特殊成像方式的-在计算机中图像通常以像素矩阵存储"><span>接着，脉冲相机在高铁检修、涡轮停机检修等方面的应用。我比较感兴趣的是基于脉冲的视觉任务。传统计算机视觉基于的图像、视频等基本是用传统相机拍摄的（当然也不排除用特殊成像方式的），在计算机中图像通常以像素矩阵存储，</span></a></h3><h3 id="而脉冲相机拍摄的脉冲序列我认为其实可以看做光子的到达时间序列-提供了更接近物理现实的记录。在脉冲序列上黄教授团队也做了一系列研究-将光流与深度估计、检测跟踪、目标识别等视觉任务基于脉冲序列进行了实现-得到了成倍的速度提升与-sota-的效果。我觉得在脉冲相机的基础上未来可以实现更类脑的神经网络并实现更接近人类视觉能力的方法。" tabindex="-1"><a class="header-anchor" href="#而脉冲相机拍摄的脉冲序列我认为其实可以看做光子的到达时间序列-提供了更接近物理现实的记录。在脉冲序列上黄教授团队也做了一系列研究-将光流与深度估计、检测跟踪、目标识别等视觉任务基于脉冲序列进行了实现-得到了成倍的速度提升与-sota-的效果。我觉得在脉冲相机的基础上未来可以实现更类脑的神经网络并实现更接近人类视觉能力的方法。"><span>而脉冲相机拍摄的脉冲序列我认为其实可以看做光子的到达时间序列，提供了更接近物理现实的记录。在脉冲序列上黄教授团队也做了一系列研究，将光流与深度估计、检测跟踪、目标识别等视觉任务基于脉冲序列进行了实现，得到了成倍的速度提升与 SOTA 的效果。我觉得在脉冲相机的基础上未来可以实现更类脑的神经网络并实现更接近人类视觉能力的方法。</span></a></h3><p>基于脉冲的视觉任务方面，黄教授团队设计并开源了 SpikeCV，即在 OpenCV 的基础上，针对脉冲序列进行了设计，还额外提供了脉冲相机的接口和已经拍摄好的数据集。地址：https://openi.pcl.ac.cn/Cordium/SpikeCV</p><p>有同学问了两个比较关心的问题，即脉冲相机的功耗会不会由于高速采样而很高？以及，脉冲相机拍摄的视频占用存储空间会不会很大？黄教授的回答基本上是，首先功耗确实会比正常大，但可以接受。其次存储由于对脉冲进行了编码，其占用带宽在 Gbps，存储空间需求虽然大但也可以在现有硬件上可以得到满足。</p><p>总之，黄教授的这次演讲干货满满，相信不久的将来可以从前沿研究真正上到我们手机上。</p>',72)]))}const t=n(e,[["render",r]]),h=JSON.parse('{"path":"/%E5%AE%9E%E4%B9%A0/%E8%84%89%E5%86%B2%E8%A7%86%E8%A7%89.html","title":"三个问题","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1754978799000,"contributors":[{"name":"ChenxiMoon","username":"ChenxiMoon","email":"2403133073@qq.com","commits":1,"url":"https://github.com/ChenxiMoon"}],"changelog":[{"hash":"58062631970f5a5952dc9d33b3ef443a454c8891","time":1754978799000,"email":"2403133073@qq.com","author":"ChenxiMoon","message":"docs: 自动更新文档"}]},"filePathRelative":"实习/脉冲视觉.md"}');export{t as comp,h as data};
